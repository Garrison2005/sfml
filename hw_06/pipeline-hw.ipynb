{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваш черед"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Новые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание творческое - придумайте по новому признаку (группе признаков)\n",
    "* На основе mcc (tr_type)\n",
    "* На основе временного фактора\n",
    "* На основе текстов из описания mcc\n",
    "\n",
    "Реалиуйте их в функции, аналогичной `gen_features`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Все закомментированные команды включены в функцию в самом конце. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "from pandas import Timestamp, DateOffset\n",
    "\n",
    "#df_gender = pd.read_csv('data/customers_gender_train.csv')\n",
    "#df_transactions = pd.read_csv('data/transactions.csv')\n",
    "#df_tr = pd.read_csv('data/tr_types.csv', sep=';')\n",
    "#df_mcc = pd.read_csv('data/tr_mcc_codes.csv', sep=';')\n",
    "\n",
    "def preproc_transactions(df_transactions):\n",
    "    sec_per_day = 86400\n",
    "    sec_per_hour = 3600\n",
    "    \n",
    "    start_date = 1420070400 - 154 * sec_per_day - 3 * sec_per_hour\n",
    "    \n",
    "    df_transactions.loc[:, 'day'] = df_transactions.tr_datetime\\\n",
    "                                               .str.split(' ')\\\n",
    "                                               .str.get(0)\\\n",
    "                                               .astype(int)\n",
    "    df_transactions.loc[:, 'time_raw'] = df_transactions.tr_datetime\\\n",
    "                                                    .str.split(' ')\\\n",
    "                                                    .str.get(1)\n",
    "\n",
    "    # set temp dt\n",
    "    df_transactions.loc[:, 'dt_temp'] = pd.to_datetime(df_transactions.loc[:, 'time_raw'], \n",
    "                                                    format='%H:%M:%S')\\\n",
    "                                        + DateOffset(years=115)\n",
    "    \n",
    "    df_transactions = df_transactions.assign(dt = lambda x: x.dt_temp.astype(np.int64) // 10**9\n",
    "                                             + (x.day - 153) * sec_per_day)\\\n",
    "                                     .assign(weekday = lambda x: ((x.day + 4) % 7 + 1))\n",
    "        \n",
    "    df_transactions.loc[:, 'datetime'] = pd.to_datetime(df_transactions.dt, unit='s')\n",
    "    df_transactions.loc[:, 'date'] = df_transactions.loc[:, 'datetime'].dt.strftime('%Y-%m-%d')\n",
    "    df_transactions.loc[:, 'hour'] = df_transactions.loc[:, 'datetime'].dt.strftime('%H')\n",
    "    \n",
    "    df_transactions = df_transactions.drop(['dt_temp', 'time_raw', 'tr_datetime'], axis=1)\n",
    "    \n",
    "    df_transactions.loc[:, 'amount'] = np.round(df_transactions.loc[:, 'amount']/(np.pi**np.exp(1)))\n",
    "            \n",
    "    return df_transactions\n",
    "\n",
    "\n",
    "#df_transactions = df_transactions.pipe(preproc_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features_1 (df_gender,df_transactions):\n",
    "    # Сначала посчитаем сумму транзакций по покупателям\n",
    "    df_tr_counts = df_transactions.pivot_table(index = ['customer_id'], columns='tr_type',values='amount', \n",
    "                             aggfunc=np.size, fill_value=0)\n",
    "       \n",
    "    df_tr_counts = df_tr_counts.rename_axis(lambda x: 'tr_{}_count'.format(x), axis=1)\n",
    "\n",
    "    df_transactions['month'] = df_transactions.date\\\n",
    "                                               .str.split('-')\\\n",
    "                                               .str.get(1)\\\n",
    "                                               .astype(int)\n",
    "    # Теперь добавим процент транзакций по сезонам\n",
    "    df_month_rations =\\\n",
    "                    df_transactions.pivot_table(index=['customer_id'],columns='month',values='amount', \n",
    "                    aggfunc=np.size, fill_value=0)\n",
    "    \n",
    "    total = df_month_rations.sum(axis=1)\n",
    "    df_month_rations.loc[:, 'winter'] = (df_month_rations[[1,2,12]].sum(axis=1).T/total).T\n",
    "    df_month_rations.loc[:, 'spring'] = (df_month_rations[[3,4,5]].sum(axis=1).T/total).T\n",
    "    df_month_rations.loc[:, 'summer'] = (df_month_rations[[6,7,8]].sum(axis=1).T/total).T\n",
    "    df_month_rations.loc[:, 'autumn'] = (df_month_rations[[9,10,11]].sum(axis=1).T/total).T\n",
    "    \n",
    "    # Добавим, например, процент оплаченных услуг,магазинов и остального\n",
    "    # По этим признакам можно отличить мужчину от женщины\n",
    "    # Пока впихнул первые попавшиеся, дальше будет зависить от конкретной задачи :) \n",
    "    df_mcc = pd.read_csv('data/tr_mcc_codes.csv', sep=';')\n",
    "    df_mcc['mcc_clast'] = 0\n",
    "    i = 0\n",
    "    while i<=df_mcc.shape[0]-1:\n",
    "        if df_mcc[['mcc_description']].values[i][0].find('услуги')>=0:\n",
    "            df_mcc['mcc_clast'][i] = 1\n",
    "        if df_mcc[['mcc_description']].values[i][0].find('магаз')>=0:\n",
    "            df_mcc['mcc_clast'][i] = 2\n",
    "        i+=1   \n",
    "    df_mcc_cl = df_mcc.pivot_table(index=['mcc_code'],columns='mcc_clast', \n",
    "                        aggfunc=np.size, fill_value=0)\n",
    "    df_mcc_cl = df_transactions.join(df_mcc_cl, on='mcc_code', how='left').iloc[:,[0,12,13,14]]\n",
    "\n",
    "\n",
    "    # Объединяем:\n",
    "    df_features = df_gender.join(df_tr_counts, on='customer_id', how='left')\\\n",
    "                        .join(df_month_rations.loc[:, ['winter', 'spring', 'summer', 'autumn']], on='customer_id', how='left')\n",
    "    ss = df_mcc_cl.groupby(['customer_id']).sum()\n",
    "    df_features =  df_features.join(ss,on='customer_id',how='left',sort = True)\n",
    "        \n",
    "    return (df_features)\n",
    "#df_features_1 = df_gender.pipe(gen_features_1, df_transactions)\n",
    "#label = 'gender'\n",
    "#idx_features1 = df_features1.columns != label\n",
    "#X1 = df_features_1.loc[:, idx_features1].values\n",
    "#y1 = df_features_1.loc[:, ~idx_features1].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию для hyperopt по перебору гипер параметров вашего пайплайна\n",
    "\n",
    "На всякий случай почитайте еще про [`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html) и [пример](http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html#sphx-glr-auto-examples-hetero-feature-union-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# А это трансформер, который выбирает подможнество столбцов из матрицы X\n",
    "# Который нужен для того, чтобы делать какие-то действия только для подмноества столбцов, \n",
    "# а потом объединять результаты\n",
    "# Через FeatureUnion\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col_idx):\n",
    "        self.col_idx = col_idx\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.col_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK, rand\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def run_trials_template(X, y, params, evals=100):\n",
    "\n",
    "    def hyperopt_cv(X, y, params):\n",
    "        \n",
    "        X_ = X.copy()\n",
    "        \n",
    "        # Отделяем параметры лог регрессии в отдельный словарь\n",
    "        lm_params = {}\n",
    "        for k, v in params.items():\n",
    "            if k.startswith('glob'):\n",
    "                continue                \n",
    "            elif k.startswith('lm'):\n",
    "                lm_params[k.split('_', 1)[1]] = v\n",
    "        \n",
    "        # Задаем шкалирование\n",
    "        if params['scaler_type'] == 'standart':\n",
    "            scaler = StandardScaler(with_mean=params['scaler_centering'])            \n",
    "        else:\n",
    "            assert params['scaler_type'] == 'robust'\n",
    "            scaler = RobustScaler(with_centering=params['scaler_centering'])\n",
    "        \n",
    "        # Создаем лог. рег. с нужными параметрами\n",
    "        clf = LogisticRegression(**lm_params,n_jobs=1)\n",
    "        \n",
    "        # Итоговый пайплайн\n",
    "        # Отделяем не нужный номер покупателя, и разделяем признаки текстовые и все остальные\n",
    "        \n",
    "        \n",
    "        a = list(range(0,78))+ list(range(81,84)) \n",
    "        selector1 = ColumnSelector(a)\n",
    "        selector2 = ColumnSelector(list(range(78,81)))\n",
    "      \n",
    "                       \n",
    "        model = Pipeline([\n",
    "            ('scaler', FeatureUnion([    \n",
    "                            ('sel_1',  Pipeline([\n",
    "                                        ('select_1', selector1),\n",
    "                                        ('scaler', scaler)\n",
    "                                                ])),\n",
    "                \n",
    "                            ('sel_2', Pipeline([\n",
    "                                        ('select_2', selector2)\n",
    "                                        \n",
    "                                                ]))\n",
    "                            \n",
    "                                    ])),\n",
    "            ('clf', clf)\n",
    "        ])\n",
    "                \n",
    "        \n",
    "         # Пока применяется scaler на обоих частях датасета\n",
    "        \n",
    "        '''model = Pipeline([\n",
    "                        ('scaler',scaler1),\n",
    "                        ('clf', clf)\n",
    "                        ])'''\n",
    "        \n",
    "        \n",
    "        \n",
    "         # Схема кросс-валидации\n",
    "        \n",
    "        n_splits = 5\n",
    "        cv = StratifiedKFold(n_splits=n_splits, shuffle=True, \n",
    "                             random_state=RND_SEED)\n",
    "        scores = cross_val_score(model, X_, y,\n",
    "                                 scoring='roc_auc', \n",
    "                                 cv=cv, \n",
    "                                 n_jobs=1)\n",
    "\n",
    "        # Возвращаем среднее значение метрики и отклонение (на всякий случай)\n",
    "        return scores.mean(), scores.std()\n",
    "\n",
    "    def f(params):\n",
    "        acc, std = hyperopt_cv(X, y, params)\n",
    "        return {'loss': -acc, 'qscore': -acc, 'qscore_std': std, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(f, \n",
    "                params, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=evals, \n",
    "                trials=trials, \n",
    "                verbose=1)\n",
    "    \n",
    "    return trials\n",
    "\n",
    "RND_SEED = 123\n",
    "space4_lm = {\n",
    "    'lm_penalty': hp.choice('penalty', ['l1', 'l2']),\n",
    "    'lm_C': hp.loguniform('C', -5, 3),\n",
    "    'lm_class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'lm_random_state': RND_SEED,\n",
    "    'scaler_type': hp.choice('scaler_type', ['standart', 'robust']),\n",
    "    'scaler_centering': hp.choice('scaler_centering', [False, True])\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def trials_df(trials):\n",
    "    '''\n",
    "    Функция форматирует результаты hyperopt в dataframe\n",
    "    '''\n",
    "    tr_dict = []\n",
    "    for t in trials:\n",
    "        trial = dict()\n",
    "        for k, v in t['misc']['vals'].items():\n",
    "            trial[k] = v[0]\n",
    "\n",
    "        trial['qscore'] = -t['result']['qscore']\n",
    "        trial['qscore_std'] = -t['result']['qscore_std']\n",
    "        tr_dict.append(trial)\n",
    "\n",
    "    df_res = pd.DataFrame.from_dict(tr_dict)\n",
    "    df_res = df_res.sort_values('qscore', ascending=False)\n",
    "    \n",
    "    return df_res\n",
    "#trials1 = run_trials_template(X1, y1, space4_lm, evals=40)\n",
    "#df_trials1 = trials_df(trials1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Lab6():\n",
    "    df_gender = pd.read_csv('data/customers_gender_train.csv')\n",
    "    df_transactions = pd.read_csv('data/transactions.csv')\n",
    "    df_tr = pd.read_csv('data/tr_types.csv', sep=';')\n",
    "    df_transactions = df_transactions.pipe(preproc_transactions)\n",
    "    df_features_1 = df_gender.pipe(gen_features_1, df_transactions)\n",
    "    label = 'gender'\n",
    "    idx_features1 = df_features_1.columns != label\n",
    "    X1 = df_features_1.loc[:, idx_features1].values\n",
    "    y1 = df_features_1.loc[:, ~idx_features1].values.flatten()\n",
    "    X1 = X1[:,1:85]\n",
    "    trials1 = run_trials_template(X1, y1, space4_lm, evals=80)\n",
    "    df_trials1 = trials_df(trials1)\n",
    "    return (df_trials1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikuznetsov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ikuznetsov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ikuznetsov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:551: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "df_trials1 = Lab6()\n",
    "df_trials1[df_trials1['qscore']==df_trials1['qscore'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "347px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "222px",
    "left": "0px",
    "right": "1247.33px",
    "top": "108px",
    "width": "182px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "40px",
   "left": "816px",
   "right": "38.6667px",
   "top": "0px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
